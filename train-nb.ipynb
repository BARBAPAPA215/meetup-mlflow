{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, auc as sk_auc, roc_curve, precision_score, recall_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import keras\n",
    "import os\n",
    "import mlflow\n",
    "from mlflow import log_metric, log_param, log_artifact\n",
    "import mlflow.sklearn\n",
    "\n",
    "seed = 42\n",
    "USE_IDF = True\n",
    "NGRAM_RANGE = (1,1)\n",
    "C = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/course_descriptions.csv\", usecols=[1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>length</th>\n",
       "      <th>course</th>\n",
       "      <th>ouid</th>\n",
       "      <th>fac</th>\n",
       "      <th>inst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>Modelling with solid elements \\r\\r\\nModelling ...</td>\n",
       "      <td>306</td>\n",
       "      <td>TEK2001</td>\n",
       "      <td>1220</td>\n",
       "      <td>IV</td>\n",
       "      <td>IV-IVB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>For further information, see www.ntnu.edu/eit ...</td>\n",
       "      <td>85</td>\n",
       "      <td>BI2097</td>\n",
       "      <td>865</td>\n",
       "      <td>NV</td>\n",
       "      <td>NV-IBI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>What is design?\\r\\r\\nDesign in the 19th centur...</td>\n",
       "      <td>1726</td>\n",
       "      <td>IMT2342</td>\n",
       "      <td>840</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD-ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>The course is given every other year, next tim...</td>\n",
       "      <td>3037</td>\n",
       "      <td>FY8203</td>\n",
       "      <td>867</td>\n",
       "      <td>NV</td>\n",
       "      <td>NV-IFY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>The course expands on and enhances the analysi...</td>\n",
       "      <td>940</td>\n",
       "      <td>MA1102</td>\n",
       "      <td>828</td>\n",
       "      <td>IE</td>\n",
       "      <td>IE-IMF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>Systems of linear equations:\\r\\r\\n- Mtrices\\r\\...</td>\n",
       "      <td>1365</td>\n",
       "      <td>REA2071F</td>\n",
       "      <td>828</td>\n",
       "      <td>IE</td>\n",
       "      <td>IE-IMF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>Optimizing algorithms for both single and mult...</td>\n",
       "      <td>868</td>\n",
       "      <td>TDT4200</td>\n",
       "      <td>827</td>\n",
       "      <td>IE</td>\n",
       "      <td>IE-IDI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>- Overview of legal sources and legal methodol...</td>\n",
       "      <td>2597</td>\n",
       "      <td>AJ200115</td>\n",
       "      <td>1138</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK-IIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>The course will cover literary representations...</td>\n",
       "      <td>1172</td>\n",
       "      <td>NORD2312</td>\n",
       "      <td>1080</td>\n",
       "      <td>HF</td>\n",
       "      <td>HF-ISL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>This course combines artistic practice and cri...</td>\n",
       "      <td>1508</td>\n",
       "      <td>BK3181</td>\n",
       "      <td>813</td>\n",
       "      <td>AD</td>\n",
       "      <td>AD-KIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description  length    course  \\\n",
       "2524  Modelling with solid elements \\r\\r\\nModelling ...     306   TEK2001   \n",
       "1751  For further information, see www.ntnu.edu/eit ...      85    BI2097   \n",
       "317   What is design?\\r\\r\\nDesign in the 19th centur...    1726   IMT2342   \n",
       "1060  The course is given every other year, next tim...    3037    FY8203   \n",
       "3684  The course expands on and enhances the analysi...     940    MA1102   \n",
       "1962  Systems of linear equations:\\r\\r\\n- Mtrices\\r\\...    1365  REA2071F   \n",
       "2643  Optimizing algorithms for both single and mult...     868   TDT4200   \n",
       "2937  - Overview of legal sources and legal methodol...    2597  AJ200115   \n",
       "1807  The course will cover literary representations...    1172  NORD2312   \n",
       "3108  This course combines artistic practice and cri...    1508    BK3181   \n",
       "\n",
       "      ouid fac    inst  \n",
       "2524  1220  IV  IV-IVB  \n",
       "1751   865  NV  NV-IBI  \n",
       "317    840  AD   AD-ID  \n",
       "1060   867  NV  NV-IFY  \n",
       "3684   828  IE  IE-IMF  \n",
       "1962   828  IE  IE-IMF  \n",
       "2643   827  IE  IE-IDI  \n",
       "2937  1138  OK  OK-IIF  \n",
       "1807  1080  HF  HF-ISL  \n",
       "3108   813  AD  AD-KIT  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['The main focus of the course is to build intelligent systems based on two key natural concepts: evolution by natural selection and swarm intelligence.  Such intelligent systems have thousands of useful applications in fields as diverse as control theory, telecommunications, music and art.  This course discusses both methods in great detail along with providing a bit of the biological basis for each.Lecture slides, a textbook (possibly 2).  Textbooks are chosen  at the beginning of the semester.Students will get both theoretical and practical programming experience with two of the best known sub-symbolic AI methods: evolutionary algorithms and swarm intelligence algorithms. ',\n",
       "        682, 'IT3708', 827, 'IE', 'IE-IDI']], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.course==\"IT3708\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IV    913\n",
       "HF    634\n",
       "IE    616\n",
       "SU    504\n",
       "NV    423\n",
       "OK    384\n",
       "MH    296\n",
       "AD    213\n",
       "Name: fac, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fac.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(document):\n",
    "    return \"\".join([ (c if c not in string.punctuation+\"\\n\\r\\t\" else \" \") for c in document])\n",
    "\n",
    "def tokenize(document):\n",
    "    return [w.lower() for w in remove_punctuation(document).split(\" \") if len(w)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = [l.strip() for l in open(\"stopwords.txt\", \"r\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'able',\n",
       " 'about',\n",
       " 'across',\n",
       " 'after',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'also',\n",
       " 'am',\n",
       " 'among',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'could',\n",
       " 'dear',\n",
       " 'did',\n",
       " 'do',\n",
       " 'does',\n",
       " 'either',\n",
       " 'else',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'for',\n",
       " 'from',\n",
       " 'get',\n",
       " 'got',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'her',\n",
       " 'hers',\n",
       " 'him',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'just',\n",
       " 'least',\n",
       " 'let',\n",
       " 'like',\n",
       " 'likely',\n",
       " 'may',\n",
       " 'me',\n",
       " 'might',\n",
       " 'most',\n",
       " 'must',\n",
       " 'my',\n",
       " 'neither',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'on',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'own',\n",
       " 'rather',\n",
       " 'said',\n",
       " 'say',\n",
       " 'says',\n",
       " 'she',\n",
       " 'should',\n",
       " 'since',\n",
       " 'so',\n",
       " 'some',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'tis',\n",
       " 'to',\n",
       " 'too',\n",
       " 'twas',\n",
       " 'us',\n",
       " 'wants',\n",
       " 'was',\n",
       " 'we',\n",
       " 'were',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2987,), (2987,), (996,), (996,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"fac\"].astype(str)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"description\"], y, stratify=y, random_state=seed)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IV    228\n",
       "HF    159\n",
       "IE    154\n",
       "SU    126\n",
       "NV    106\n",
       "OK     96\n",
       "MH     74\n",
       "AD     53\n",
       "Name: fac, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IV    685\n",
       "HF    475\n",
       "IE    462\n",
       "SU    378\n",
       "NV    317\n",
       "OK    288\n",
       "MH    222\n",
       "AD    160\n",
       "Name: fac, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(tokenizer=tokenize, stop_words=stoplist, use_idf=USE_IDF, ngram_range=NGRAM_RANGE)\n",
    "trn_vec= vec.fit_transform(X_train.values)\n",
    "test_vec = vec.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2987, 9), (996, 9))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.concat([X_train, pd.get_dummies(y_train)], axis=1)\n",
    "X_test = pd.concat([X_test, pd.get_dummies(y_test)], axis=1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>AD</th>\n",
       "      <th>HF</th>\n",
       "      <th>IE</th>\n",
       "      <th>IV</th>\n",
       "      <th>MH</th>\n",
       "      <th>NV</th>\n",
       "      <th>OK</th>\n",
       "      <th>SU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>NEVR2010 provides a thorough introduction to c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>Hypothesis testing. Simple and multiple linear...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>Specialization is offered in a variety of topi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>The subject gives a broad introduction to the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>Didactics is the theoretical and practical kno...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description  AD  HF  IE  IV  MH  \\\n",
       "2830  NEVR2010 provides a thorough introduction to c...   0   0   0   0   1   \n",
       "529   Hypothesis testing. Simple and multiple linear...   0   0   1   0   0   \n",
       "787   Specialization is offered in a variety of topi...   0   0   0   1   0   \n",
       "564   The subject gives a broad introduction to the ...   0   1   0   0   0   \n",
       "1655  Didactics is the theoretical and practical kno...   0   0   0   0   0   \n",
       "\n",
       "      NV  OK  SU  \n",
       "2830   0   0   0  \n",
       "529    0   0   0  \n",
       "787    0   0   0  \n",
       "564    0   0   0  \n",
       "1655   0   0   1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IE', 'HF', 'IV', 'AD', 'SU', 'MH', 'NV', 'OK']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(996, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cols = df[\"fac\"].astype(str).unique().tolist()\n",
    "print(label_cols)\n",
    "preds = np.zeros((len(X_test), len(label_cols)))\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2987, 21404), (996, 21404), (996, 9))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_vec.shape,test_vec.shape,  X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior(y_i, y):\n",
    "    '''\n",
    "    y_i is either 1 or 0.\n",
    "    y is numpy array of labels\n",
    "    '''\n",
    "    p = trn_vec[y==y_i].sum(0) # Number of documents in trn_doc with given label\n",
    "    return (p+1) / ((y==y_i).sum()+1) # Fraction of all documents with given label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mdl(y):\n",
    "    y = y.values #pandas Series to numpy array\n",
    "    r = np.log(prior(1,y) / prior(0,y)) #Log likelihood ratio for both possibilities\n",
    "    m = LogisticRegression(C=C, solver=\"liblinear\") # Logistic regression model\n",
    "    x_nb = trn_vec.multiply(r) # Multiply the Tf-idf features with this ratio\n",
    "    return m.fit(x_nb, y), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(trn_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = clf.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "627"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p == y_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 83,   1,  70,   0,   0,   0,   0,   0],\n",
       "       [  2, 144,  10,   0,   3,   0,   0,   0],\n",
       "       [  2,   0, 225,   0,   0,   0,   1,   0],\n",
       "       [  2,   7,  42,   1,   1,   0,   0,   0],\n",
       "       [  0,  11,  21,   0,  94,   0,   0,   0],\n",
       "       [  1,   1,  34,   0,  10,  27,   1,   0],\n",
       "       [  1,   1,  76,   0,   0,   0,  28,   0],\n",
       "       [  1,   4,  64,   0,   2,   0,   0,  25]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, p, labels=label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IE', 'HF', 'IV', 'AD', 'SU', 'MH', 'NV', 'OK']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IV    228\n",
       "HF    159\n",
       "IE    154\n",
       "SU    126\n",
       "NV    106\n",
       "OK     96\n",
       "MH     74\n",
       "AD     53\n",
       "Name: fac, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True\n",
    "SAVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit IE\n",
      "fit HF\n",
      "fit IV\n",
      "fit AD\n",
      "fit SU\n",
      "fit MH\n",
      "fit NV\n",
      "fit OK\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "rs = {}\n",
    "for i, j in enumerate(label_cols):\n",
    "    print('fit', j)\n",
    "    m,r = get_mdl(X_train[j])\n",
    "    if TRAIN:\n",
    "        preds[:,i] = m.predict_proba(test_vec.multiply(r))[:,1]\n",
    "    else:\n",
    "        if SAVE:\n",
    "            np.save(open(\"webapp/r_\"+j+\".npy\", \"wb\"), r)\n",
    "            pickle.dump(m, open(\"webapp/\"+j+\"_model.pkl\", \"wb\"))\n",
    "    models[j] = m\n",
    "    rs[j] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame(preds, columns=label_cols)\n",
    "\n",
    "for c in df_preds.columns:\n",
    "    df_preds[c+\"_predicted\"] = (df_preds.max(axis=1)==df_preds[c]).astype(int)\n",
    "\n",
    "oh_y_test = pd.get_dummies(y_test)\n",
    "oh_y_test = oh_y_test.rename({c:c+\"_actual\" for c in oh_y_test.columns},axis=1)\n",
    "\n",
    "df_preds = pd.concat([df_preds, oh_y_test.reset_index()], axis=1)\n",
    "\n",
    "res_df = pd.DataFrame(confusion_matrix(df_preds.loc[:,[c+\"_actual\" for c in label_cols]].values.argmax(1), df_preds.loc[:,[c+\"_predicted\" for c in label_cols]].values.argmax(1)), index=label_cols, columns=label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IE</th>\n",
       "      <th>HF</th>\n",
       "      <th>IV</th>\n",
       "      <th>AD</th>\n",
       "      <th>SU</th>\n",
       "      <th>MH</th>\n",
       "      <th>NV</th>\n",
       "      <th>OK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IE</th>\n",
       "      <td>134</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HF</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IV</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SU</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MH</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NV</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OK</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     IE   HF   IV  AD   SU  MH  NV  OK\n",
       "IE  134    2   12   1    0   0   3   2\n",
       "HF    1  151    1   0    4   0   0   2\n",
       "IV   12    0  203   3    0   0   5   5\n",
       "AD    8    1    5  35    3   0   0   1\n",
       "SU    4    2    4   0  113   0   1   2\n",
       "MH    2    0    4   0    5  60   3   0\n",
       "NV    7    0    6   0    0   5  88   0\n",
       "OK    4    4    5   0    7   0   0  76"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8634538152610441"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(df_preds.loc[:,[c+\"_actual\" for c in label_cols]].values.argmax(1), df_preds.loc[:,[c+\"_predicted\" for c in label_cols]].values.argmax(1), average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8736078613731231"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(df_preds.loc[:,[c+\"_actual\" for c in label_cols]].values.argmax(1), df_preds.loc[:,[c+\"_predicted\" for c in label_cols]].values.argmax(1), average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77906977, 0.94375   , 0.84583333, 0.8974359 , 0.85606061,\n",
       "       0.92307692, 0.88      , 0.86363636])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(df_preds.loc[:,[c+\"_actual\" for c in label_cols]].values.argmax(1), df_preds.loc[:,[c+\"_predicted\" for c in label_cols]].values.argmax(1), average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Define metrics\n",
    "- Plot\n",
    "- Script evolution\n",
    "- Think about steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Log a parameter (key-value pair)\n",
    "log_param(\"param1\", 5)\n",
    "\n",
    "# Log a metric; metrics can be updated throughout the run\n",
    "log_metric(\"foo\", 1)\n",
    "log_metric(\"foo\", 2)\n",
    "log_metric(\"foo\", 3)\n",
    "\n",
    "# Log an artifact (output file)\n",
    "with open(\"output.txt\", \"w\") as f:\n",
    "    f.write(\"Hello world!\")\n",
    "log_artifact(\"output.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLmodel  conda.yaml  python_model.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/thomas/meetup-mlflow/mlruns/0/06001c30d2f14207a2ceb33996ce2b58/artifacts/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cloudpickle.load(open(\"/home/thomas/meetup-mlflow/mlruns/0/06001c30d2f14207a2ceb33996ce2b58/artifacts/models/python_model.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MH'], dtype='<U2')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(None, [\"medical\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "The ``mlflow.pyfunc.model`` module defines logic for saving and loading custom \"python_function\"\n",
      "models with a user-defined ``PythonModel`` subclass.\n",
      "\"\"\"\n",
      "\n",
      "import os\n",
      "import tempfile\n",
      "import shutil\n",
      "import yaml\n",
      "from abc import ABCMeta, abstractmethod\n",
      "\n",
      "import cloudpickle\n",
      "\n",
      "import mlflow.pyfunc\n",
      "import mlflow.utils\n",
      "from mlflow.exceptions import MlflowException\n",
      "from mlflow.models import Model\n",
      "from mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE, RESOURCE_ALREADY_EXISTS\n",
      "from mlflow.tracking.utils import _download_artifact_from_uri\n",
      "from mlflow.utils.environment import _mlflow_conda_env\n",
      "from mlflow.utils.model_utils import _get_flavor_configuration\n",
      "from mlflow.utils.file_utils import TempDir, _copy_file_or_tree\n",
      "\n",
      "# `DEFAULT_CONDA_ENV` defines the default Conda environment for models produced by calls to\n",
      "# `mlflow.pyfunc.save_model()` and `mlflow.pyfunc.log_model()` when a user-defined subclass of\n",
      "# ``PythonModel`` is provided.\n",
      "DEFAULT_CONDA_ENV = _mlflow_conda_env(\n",
      "    additional_conda_deps=None,\n",
      "    additional_pip_deps=[\n",
      "        \"cloudpickle=={}\".format(cloudpickle.__version__),\n",
      "    ],\n",
      "    additional_conda_channels=None,\n",
      ")\n",
      "\n",
      "CONFIG_KEY_ARTIFACTS = \"artifacts\"\n",
      "CONFIG_KEY_ARTIFACT_RELATIVE_PATH = \"path\"\n",
      "CONFIG_KEY_ARTIFACT_URI = \"uri\"\n",
      "CONFIG_KEY_PYTHON_MODEL = \"python_model\"\n",
      "CONFIG_KEY_CLOUDPICKLE_VERSION = \"cloudpickle_version\"\n",
      "\n",
      "\n",
      "class PythonModel(object):\n",
      "    \"\"\"\n",
      "    Represents a generic Python model that evaluates inputs and produces API-compatible outputs.\n",
      "    By subclassing :class:`~PythonModel`, users can create customized MLflow models with the\n",
      "    \"python_function\" (\"pyfunc\") flavor, leveraging custom inference logic and artifact\n",
      "    dependencies.\n",
      "    \"\"\"\n",
      "    __metaclass__ = ABCMeta\n",
      "\n",
      "    def load_context(self, context):\n",
      "        \"\"\"\n",
      "        Loads artifacts from the specified :class:`~PythonModelContext` that can be used by\n",
      "        :func:`~PythonModel.predict` when evaluating inputs. When loading an MLflow model with\n",
      "        :func:`~load_pyfunc`, this method will be called as soon as the :class:`~PythonModel` is\n",
      "        constructed.\n",
      "\n",
      "        The same :class:`~PythonModelContext` will also be available during calls to\n",
      "        :func:`~PythonModel.predict`, but it may be more efficient to override this method\n",
      "        and load artifacts from the context at model load time.\n",
      "\n",
      "        :param context: A :class:`~PythonModelContext` instance containing artifacts that the model\n",
      "                        can use to perform inference.\n",
      "        \"\"\"\n",
      "\n",
      "    @abstractmethod\n",
      "    def predict(self, context, model_input):\n",
      "        \"\"\"\n",
      "        Evaluates a pyfunc-compatible input and produces a pyfunc-compatible output.\n",
      "        For more information about the pyfunc input/output API, see the :ref:`pyfunc-inference-api`.\n",
      "\n",
      "        :param context: A :class:`~PythonModelContext` instance containing artifacts that the model\n",
      "                        can use to perform inference.\n",
      "        :param model_input: A pyfunc-compatible input for the model to evaluate.\n",
      "        \"\"\"\n",
      "\n",
      "\n",
      "class PythonModelContext(object):\n",
      "    \"\"\"\n",
      "    A collection of artifacts that a :class:`~PythonModel` can use when performing inference.\n",
      "    :class:`~PythonModelContext` objects are created *implicitly* by the\n",
      "    :func:`save_model() <mlflow.pyfunc.save_model>` and\n",
      "    :func:`log_model() <mlflow.pyfunc.log_model>` persistence methods, using the contents specified\n",
      "    by the ``artifacts`` parameter of these methods.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, artifacts):\n",
      "        \"\"\"\n",
      "        :param artifacts: A dictionary of ``<name, artifact_path>`` entries, where ``artifact_path``\n",
      "                          is an absolute filesystem path to a given artifact.\n",
      "        \"\"\"\n",
      "        self._artifacts = artifacts\n",
      "\n",
      "    @property\n",
      "    def artifacts(self):\n",
      "        \"\"\"\n",
      "        :return: A dictionary containing ``<name, artifact_path>`` entries, where ``artifact_path``\n",
      "                 is an absolute filesystem path to the artifact.\n",
      "        \"\"\"\n",
      "        return self._artifacts\n",
      "\n",
      "\n",
      "def _save_model_with_class_artifacts_params(path, python_model, artifacts=None, conda_env=None,\n",
      "                                            code_paths=None, mlflow_model=Model()):\n",
      "    \"\"\"\n",
      "    :param path: The path to which to save the Python model.\n",
      "    :param python_model: An instance of a subclass of :class:`~PythonModel`. ``python_model``\n",
      "                        defines how the model loads artifacts and how it performs inference.\n",
      "    :param artifacts: A dictionary containing ``<name, artifact_uri>`` entries. Remote artifact URIs\n",
      "                      will be resolved to absolute filesystem paths, producing a dictionary of\n",
      "                      ``<name, absolute_path>`` entries. ``python_model`` can reference these\n",
      "                      resolved entries as the ``artifacts`` property of the ``context`` attribute.\n",
      "                      If *None*, no artifacts will be added to the model.\n",
      "    :param conda_env: Either a dictionary representation of a Conda environment or the path to a\n",
      "                      Conda environment yaml file. If provided, this decribes the environment\n",
      "                      this model should be run in. At minimum, it should specify the dependencies\n",
      "                      contained in :data:`mlflow.pyfunc.DEFAULT_CONDA_ENV`. If `None`, the default\n",
      "                      :data:`mlflow.pyfunc.DEFAULT_CONDA_ENV` environment will be added to the\n",
      "                      model.\n",
      "    :param code_paths: A list of local filesystem paths to Python file dependencies (or directories\n",
      "                       containing file dependencies). These files will be *prepended* to the system\n",
      "                       path before the model is loaded.\n",
      "    :param mlflow_model: The model configuration to which to add the ``mlflow.pyfunc`` flavor.\n",
      "    \"\"\"\n",
      "    if os.path.exists(path):\n",
      "        raise MlflowException(\n",
      "                message=\"Path '{}' already exists\".format(path),\n",
      "                error_code=RESOURCE_ALREADY_EXISTS)\n",
      "    os.makedirs(path)\n",
      "\n",
      "    custom_model_config_kwargs = {\n",
      "        CONFIG_KEY_CLOUDPICKLE_VERSION: cloudpickle.__version__,\n",
      "    }\n",
      "    if isinstance(python_model, PythonModel):\n",
      "        saved_python_model_subpath = \"python_model.pkl\"\n",
      "        with open(os.path.join(path, saved_python_model_subpath), \"wb\") as out:\n",
      "            cloudpickle.dump(python_model, out)\n",
      "        custom_model_config_kwargs[CONFIG_KEY_PYTHON_MODEL] = saved_python_model_subpath\n",
      "    else:\n",
      "        raise MlflowException(\n",
      "                message=(\"`python_model` must be a subclass of `PythonModel`. Instead, found an\"\n",
      "                         \" object of type: {python_model_type}\".format(\n",
      "                             python_model_type=type(python_model))),\n",
      "                error_code=INVALID_PARAMETER_VALUE)\n",
      "\n",
      "    if artifacts:\n",
      "        saved_artifacts_config = {}\n",
      "        with TempDir() as tmp_artifacts_dir:\n",
      "            tmp_artifacts_config = {}\n",
      "            saved_artifacts_dir_subpath = \"artifacts\"\n",
      "            for artifact_name, artifact_uri in artifacts.items():\n",
      "                tmp_artifact_path = _download_artifact_from_uri(\n",
      "                    artifact_uri=artifact_uri, output_path=tmp_artifacts_dir.path())\n",
      "                tmp_artifacts_config[artifact_name] = tmp_artifact_path\n",
      "                saved_artifact_subpath = os.path.join(\n",
      "                    saved_artifacts_dir_subpath,\n",
      "                    os.path.relpath(path=tmp_artifact_path, start=tmp_artifacts_dir.path()))\n",
      "                saved_artifacts_config[artifact_name] = {\n",
      "                    CONFIG_KEY_ARTIFACT_RELATIVE_PATH: saved_artifact_subpath,\n",
      "                    CONFIG_KEY_ARTIFACT_URI: artifact_uri,\n",
      "                }\n",
      "\n",
      "            shutil.move(tmp_artifacts_dir.path(), os.path.join(path, saved_artifacts_dir_subpath))\n",
      "        custom_model_config_kwargs[CONFIG_KEY_ARTIFACTS] = saved_artifacts_config\n",
      "\n",
      "    conda_env_subpath = \"conda.yaml\"\n",
      "    if conda_env is None:\n",
      "        conda_env = DEFAULT_CONDA_ENV\n",
      "    elif not isinstance(conda_env, dict):\n",
      "        with open(conda_env, \"r\") as f:\n",
      "            conda_env = yaml.safe_load(f)\n",
      "    with open(os.path.join(path, conda_env_subpath), \"w\") as f:\n",
      "        yaml.safe_dump(conda_env, stream=f, default_flow_style=False)\n",
      "\n",
      "    saved_code_subpath = None\n",
      "    if code_paths is not None:\n",
      "        saved_code_subpath = \"code\"\n",
      "        for code_path in code_paths:\n",
      "            _copy_file_or_tree(src=code_path, dst=path, dst_dir=saved_code_subpath)\n",
      "\n",
      "    mlflow.pyfunc.add_to_model(model=mlflow_model, loader_module=__name__, code=saved_code_subpath,\n",
      "                               env=conda_env_subpath, **custom_model_config_kwargs)\n",
      "    mlflow_model.save(os.path.join(path, 'MLmodel'))\n",
      "\n",
      "\n",
      "def _load_pyfunc(model_path):\n",
      "    pyfunc_config = _get_flavor_configuration(\n",
      "            model_path=model_path, flavor_name=mlflow.pyfunc.FLAVOR_NAME)\n",
      "\n",
      "    python_model_cloudpickle_version = pyfunc_config.get(CONFIG_KEY_CLOUDPICKLE_VERSION, None)\n",
      "    if python_model_cloudpickle_version is None:\n",
      "        mlflow.pyfunc._logger.warning(\n",
      "            \"The version of CloudPickle used to save the model could not be found in the MLmodel\"\n",
      "            \" configuration\")\n",
      "    elif python_model_cloudpickle_version != cloudpickle.__version__:\n",
      "        # CloudPickle does not have a well-defined cross-version compatibility policy. Micro version\n",
      "        # releases have been known to cause incompatibilities. Therefore, we match on the full\n",
      "        # library version\n",
      "        mlflow.pyfunc._logger.warning(\n",
      "            \"The version of CloudPickle that was used to save the model, `CloudPickle %s`, differs\"\n",
      "            \" from the version of CloudPickle that is currently running, `CloudPickle %s`, and may\"\n",
      "            \" be incompatible\",\n",
      "            python_model_cloudpickle_version, cloudpickle.__version__)\n",
      "\n",
      "    python_model_subpath = pyfunc_config.get(CONFIG_KEY_PYTHON_MODEL, None)\n",
      "    if python_model_subpath is None:\n",
      "        raise MlflowException(\n",
      "            \"Python model path was not specified in the model configuration\")\n",
      "    with open(os.path.join(model_path, python_model_subpath), \"rb\") as f:\n",
      "        python_model = cloudpickle.load(f)\n",
      "\n",
      "    # TODO: If the longevity of the temporary directory prior becomes problematic, consider using\n",
      "    # an alternative solution.\n",
      "    tmp_artifacts_dir_path = tempfile.mkdtemp(suffix=\"artifacts\")\n",
      "    artifacts = {}\n",
      "    for saved_artifact_name, saved_artifact_info in\\\n",
      "            pyfunc_config.get(CONFIG_KEY_ARTIFACTS, {}).items():\n",
      "        tmp_artifact_path = os.path.join(\n",
      "                tmp_artifacts_dir_path,\n",
      "                _copy_file_or_tree(\n",
      "                    src=os.path.join(\n",
      "                        model_path, saved_artifact_info[CONFIG_KEY_ARTIFACT_RELATIVE_PATH]),\n",
      "                    dst=tmp_artifacts_dir_path,\n",
      "                    dst_dir=saved_artifact_name))\n",
      "        artifacts[saved_artifact_name] = tmp_artifact_path\n",
      "\n",
      "    context = PythonModelContext(artifacts=artifacts)\n",
      "    python_model.load_context(context=context)\n",
      "    return _PythonModelPyfuncWrapper(python_model=python_model, context=context)\n",
      "\n",
      "\n",
      "class _PythonModelPyfuncWrapper(object):\n",
      "    \"\"\"\n",
      "    Wrapper class that creates a predict function such that\n",
      "    predict(model_input: pd.DataFrame) -> model's output as pd.DataFrame (pandas DataFrame)\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, python_model, context):\n",
      "        \"\"\"\n",
      "        :param python_model: An instance of a subclass of :class:`~PythonModel`.\n",
      "        :param context: A :class:`~PythonModelContext` instance containing artifacts that\n",
      "                        ``python_model`` may use when performing inference.\n",
      "        \"\"\"\n",
      "        self.python_model = python_model\n",
      "        self.context = context\n",
      "\n",
      "    def predict(self, model_input):\n",
      "        return self.python_model.predict(self.context, model_input)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/thomas/anaconda3/envs/mlflow-1e36aa13ae6dbb8cebcb85017053388003b77ffa/lib/python3.7/site-packages/mlflow/pyfunc/model.py\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
